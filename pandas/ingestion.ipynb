{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlined Data Ingestion with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!curl -s --insecure -o vt_tax_data_2016.csv https://assets.datacamp.com/production/repositories/4412/datasets/61bb27bf939aac4344d4f446ce6da1d1bf534174/vt_tax_data_2016.csv\n",
    "!curl -s --insecure -o fcc-new-coder-survey.xlsx https://assets.datacamp.com/production/repositories/4412/datasets/fdb113aa942a0e0ad5c155b2f04784886f0038c9/fcc-new-coder-survey.xlsx\n",
    "!curl -s --insecure -o data.db https://assets.datacamp.com/production/repositories/4412/datasets/86d5855fd30d02afe8cb563da6057190694c6b86/data.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data from Flat Files\n",
    "\n",
    "### Introduction to Flat Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "(100, 147)\n",
      "---\n",
      "STATEFIPS     int64\n",
      "STATE        object\n",
      "zipcode      object\n",
      "agi_stub      int64\n",
      "N1            int64\n",
      "              ...  \n",
      "A85300        int64\n",
      "N11901        int64\n",
      "A11901        int64\n",
      "N11902        int64\n",
      "A11902        int64\n",
      "Length: 147, dtype: object\n",
      "---\n",
      "   STATEFIPS STATE zipcode  agi_stub      N1  mars1  MARS2  MARS4   PREP  \\\n",
      "0         50    VT     NaN         1  111580  85090  14170  10740  45360   \n",
      "1         50    VT     NaN         2   82760  51960  18820  11310  35600   \n",
      "2         50    VT     NaN         3   46270  19540  22650   3620  24140   \n",
      "3         50    VT     NaN         4   30070   5830  22190    960  16060   \n",
      "4         50    VT     NaN         5   39530   3900  33800    590  22500   \n",
      "5         50    VT     NaN         6    9620    600   8150      0   7040   \n",
      "\n",
      "       N2  ...  N10300  A10300  N85530  A85530  N85300  A85300  N11901  \\\n",
      "0  130630  ...   53660   50699       0       0       0       0   10820   \n",
      "1  132950  ...   74340  221146       0       0       0       0   12820   \n",
      "2   91870  ...   44860  266097       0       0       0       0   10810   \n",
      "3   71610  ...   29580  264678       0       0       0       0    7320   \n",
      "4  103710  ...   39170  731963      40      24       0       0   12500   \n",
      "5   26430  ...    9600  894432    3350    4939    4990   20428    3900   \n",
      "\n",
      "   A11901  N11902  A11902  \n",
      "0    9734   88260  138337  \n",
      "1   20029   68760  151729  \n",
      "2   24499   34600   90583  \n",
      "3   21573   21300   67045  \n",
      "4   67761   23320  103034  \n",
      "5   93123    2870   39425  \n",
      "\n",
      "[6 rows x 147 columns]\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slavo\\AppData\\Local\\Temp\\ipykernel_21444\\1556121908.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(\"vt_tax_data_2016.csv\",\n",
      "C:\\Users\\slavo\\AppData\\Local\\Temp\\ipykernel_21444\\1556121908.py:5: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(\"vt_tax_data_2016.csv\",\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATEFIPS</th>\n",
       "      <th>STATE</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>agi_stub</th>\n",
       "      <th>N1</th>\n",
       "      <th>mars1</th>\n",
       "      <th>MARS2</th>\n",
       "      <th>MARS4</th>\n",
       "      <th>PREP</th>\n",
       "      <th>N2</th>\n",
       "      <th>...</th>\n",
       "      <th>N10300</th>\n",
       "      <th>A10300</th>\n",
       "      <th>N85530</th>\n",
       "      <th>A85530</th>\n",
       "      <th>N85300</th>\n",
       "      <th>A85300</th>\n",
       "      <th>N11901</th>\n",
       "      <th>A11901</th>\n",
       "      <th>N11902</th>\n",
       "      <th>A11902</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>VT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>111580</td>\n",
       "      <td>85090</td>\n",
       "      <td>14170</td>\n",
       "      <td>10740</td>\n",
       "      <td>45360</td>\n",
       "      <td>130630</td>\n",
       "      <td>...</td>\n",
       "      <td>53660</td>\n",
       "      <td>50699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10820</td>\n",
       "      <td>9734</td>\n",
       "      <td>88260</td>\n",
       "      <td>138337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>VT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>82760</td>\n",
       "      <td>51960</td>\n",
       "      <td>18820</td>\n",
       "      <td>11310</td>\n",
       "      <td>35600</td>\n",
       "      <td>132950</td>\n",
       "      <td>...</td>\n",
       "      <td>74340</td>\n",
       "      <td>221146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12820</td>\n",
       "      <td>20029</td>\n",
       "      <td>68760</td>\n",
       "      <td>151729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>VT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>46270</td>\n",
       "      <td>19540</td>\n",
       "      <td>22650</td>\n",
       "      <td>3620</td>\n",
       "      <td>24140</td>\n",
       "      <td>91870</td>\n",
       "      <td>...</td>\n",
       "      <td>44860</td>\n",
       "      <td>266097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10810</td>\n",
       "      <td>24499</td>\n",
       "      <td>34600</td>\n",
       "      <td>90583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>VT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>30070</td>\n",
       "      <td>5830</td>\n",
       "      <td>22190</td>\n",
       "      <td>960</td>\n",
       "      <td>16060</td>\n",
       "      <td>71610</td>\n",
       "      <td>...</td>\n",
       "      <td>29580</td>\n",
       "      <td>264678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7320</td>\n",
       "      <td>21573</td>\n",
       "      <td>21300</td>\n",
       "      <td>67045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>VT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>39530</td>\n",
       "      <td>3900</td>\n",
       "      <td>33800</td>\n",
       "      <td>590</td>\n",
       "      <td>22500</td>\n",
       "      <td>103710</td>\n",
       "      <td>...</td>\n",
       "      <td>39170</td>\n",
       "      <td>731963</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>67761</td>\n",
       "      <td>23320</td>\n",
       "      <td>103034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATEFIPS STATE zipcode  agi_stub      N1  mars1  MARS2  MARS4   PREP  \\\n",
       "0         50    VT     NaN         1  111580  85090  14170  10740  45360   \n",
       "1         50    VT     NaN         2   82760  51960  18820  11310  35600   \n",
       "2         50    VT     NaN         3   46270  19540  22650   3620  24140   \n",
       "3         50    VT     NaN         4   30070   5830  22190    960  16060   \n",
       "4         50    VT     NaN         5   39530   3900  33800    590  22500   \n",
       "\n",
       "       N2  ...  N10300  A10300  N85530  A85530  N85300  A85300  N11901  \\\n",
       "0  130630  ...   53660   50699       0       0       0       0   10820   \n",
       "1  132950  ...   74340  221146       0       0       0       0   12820   \n",
       "2   91870  ...   44860  266097       0       0       0       0   10810   \n",
       "3   71610  ...   29580  264678       0       0       0       0    7320   \n",
       "4  103710  ...   39170  731963      40      24       0       0   12500   \n",
       "\n",
       "   A11901  N11902  A11902  \n",
       "0    9734   88260  138337  \n",
       "1   20029   68760  151729  \n",
       "2   24499   34600   90583  \n",
       "3   21573   21300   67045  \n",
       "4   67761   23320  103034  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "col_names = [\"STATEFIPS\", \"STATE\", \"zipcode\", \"agi_stub\", \"N1\"]\n",
    "col_nums = [0,1,2,3,4]\n",
    "df = pd.read_csv(\"vt_tax_data_2016.csv\",\n",
    "    sep=\",\",\n",
    "    #usecols=col_names, # or col_nums\n",
    "    nrows=100,\n",
    "    #skiprows=1000,\n",
    "    #header=None,\n",
    "    #names=col_names,\n",
    "    dtype={\"zipcode\": \"str\"},\n",
    "    na_values={\"zipcode\": 0},\n",
    "    error_bad_lines=False,\n",
    "    warn_bad_lines=True,\n",
    "    )\n",
    "print(\"---\")\n",
    "print(df.shape)\n",
    "print(\"---\")\n",
    "print(df.dtypes)\n",
    "print(\"---\")\n",
    "print(df[df.zipcode.isna()])\n",
    "print(\"---\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to spreadsheets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Spreadsheets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "survey_data = pd.read_excel(\"fcc-new-coder-survey.xlsx\")\n",
    "survey_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommuteTime</th>\n",
       "      <th>CountryCitizen</th>\n",
       "      <th>CountryLive</th>\n",
       "      <th>EmploymentField</th>\n",
       "      <th>EmploymentFieldOther</th>\n",
       "      <th>EmploymentStatus</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.0</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>office and administrative support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>32000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.0</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>food and beverage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>15000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>finance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.0</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>arts, entertainment, sports, or media</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>43000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employed for wages</td>\n",
       "      <td>6000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CommuteTime            CountryCitizen               CountryLive  \\\n",
       "0         35.0  United States of America  United States of America   \n",
       "1         90.0  United States of America  United States of America   \n",
       "2         45.0  United States of America  United States of America   \n",
       "3         45.0  United States of America  United States of America   \n",
       "4         10.0  United States of America  United States of America   \n",
       "\n",
       "                         EmploymentField EmploymentFieldOther  \\\n",
       "0      office and administrative support                  NaN   \n",
       "1                      food and beverage                  NaN   \n",
       "2                                finance                  NaN   \n",
       "3  arts, entertainment, sports, or media                  NaN   \n",
       "4                              education                  NaN   \n",
       "\n",
       "     EmploymentStatus   Income  \n",
       "0  Employed for wages  32000.0  \n",
       "1  Employed for wages  15000.0  \n",
       "2  Employed for wages  48000.0  \n",
       "3  Employed for wages  43000.0  \n",
       "4  Employed for wages   6000.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_data = pd.read_excel(\"fcc-new-coder-survey.xlsx\",\n",
    "                            skiprows=2,\n",
    "                            usecols=\"W:AB,AR\")\n",
    "survey_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from multiple worksheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data = pd.read_excel(\"fcc-new-coder-survey.xlsx\",\n",
    "                            sheet_name=[\"2017\"], # or None for all sheets\n",
    "                            )\n",
    "survey_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016' '2017']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slavo\\AppData\\Local\\Temp\\ipykernel_21444\\2687876290.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_responses = all_responses.append(frame)\n",
      "C:\\Users\\slavo\\AppData\\Local\\Temp\\ipykernel_21444\\2687876290.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_responses = all_responses.append(frame)\n"
     ]
    }
   ],
   "source": [
    "survey_responses = pd.read_excel(\"fcc-new-coder-survey.xlsx\",\n",
    "                                 sheet_name=None)\n",
    "\n",
    "all_responses = pd.DataFrame()\n",
    "\n",
    "for sheet_name, frame in survey_responses.items():\n",
    "    frame[\"Year\"] = sheet_name\n",
    "    all_responses = all_responses.append(frame)\n",
    "\n",
    "print(all_responses.Year.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying imports: true/false data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'AttendedBootcamp', 'BootcampFinish', 'BootcampLoanYesNo',\n",
      "       'BootcampName', 'BootcampRecommend', 'ChildrenNumber', 'CityPopulation',\n",
      "       'CodeEventConferences', 'CodeEventDjangoGirls', 'CodeEventGameJam',\n",
      "       'CodeEventGirlDev', 'CodeEventHackathons', 'CodeEventMeetup',\n",
      "       'CodeEventNodeSchool', 'CodeEventNone', 'CodeEventOther',\n",
      "       'CodeEventRailsBridge', 'CodeEventRailsGirls', 'CodeEventStartUpWknd',\n",
      "       'CodeEventWomenCode', 'CodeEventWorkshop', 'CommuteTime',\n",
      "       'CountryCitizen', 'CountryLive', 'EmploymentField',\n",
      "       'EmploymentFieldOther', 'EmploymentStatus', 'EmploymentStatusOther',\n",
      "       'ExpectedEarning', 'FinanciallySupporting', 'Gender', 'HasChildren',\n",
      "       'HasDebt', 'HasFinancialDependents', 'HasHighSpdInternet',\n",
      "       'HasHomeMortgage', 'HasServedInMilitary', 'HasStudentDebt',\n",
      "       'HomeMortgageOwe', 'HoursLearning', 'ID.x', 'ID.y', 'Income',\n",
      "       'IsEthnicMinority', 'IsReceiveDisabilitiesBenefits', 'IsSoftwareDev',\n",
      "       'IsUnderEmployed', 'JobApplyWhen', 'JobPref', 'JobRelocateYesNo',\n",
      "       'JobRoleInterest', 'JobWherePref', 'LanguageAtHome', 'MaritalStatus',\n",
      "       'MoneyForLearning', 'MonthsProgramming', 'NetworkID', 'Part1EndTime',\n",
      "       'Part1StartTime', 'Part2EndTime', 'Part2StartTime', 'PodcastChangeLog',\n",
      "       'PodcastCodeNewbie', 'PodcastDeveloperTea', 'PodcastDotNetRocks',\n",
      "       'PodcastJsAir', 'PodcastJSJabber', 'PodcastNone', 'PodcastOther',\n",
      "       'PodcastProgrammingThrowDown', 'PodcastRubyRogues', 'PodcastSEDaily',\n",
      "       'PodcastShopTalk', 'PodcastTalkPython', 'PodcastWebAhead',\n",
      "       'ResourceCodecademy', 'ResourceCodeWars', 'ResourceCoursera',\n",
      "       'ResourceEdX', 'ResourceEggHead', 'ResourceFCC', 'ResourceHackerRank',\n",
      "       'ResourceKhanAcademy', 'ResourceLynda', 'ResourceMDN',\n",
      "       'ResourceOdinProj', 'ResourceOther', 'ResourcePluralSight',\n",
      "       'ResourceSkillCrush', 'ResourceStackOverflow', 'ResourceTreehouse',\n",
      "       'ResourceUdacity', 'ResourceUdemy', 'ResourceW3Schools', 'SchoolDegree',\n",
      "       'SchoolMajor', 'StudentDebtOwe'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m      6\u001b[0m df \u001b[39m=\u001b[39m df[[\u001b[39m\"\u001b[39m\u001b[39mAttendedBootcamp\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mBootcampLoanYesNo\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m----> 8\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mAttendedBootcampTF\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTRUE\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m df[\u001b[39m\"\u001b[39m\u001b[39mAttendedBootcamp\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mFALSE\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m df[\u001b[39m\"\u001b[39m\u001b[39mAttendedBootcamp\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m#df[\"AttendedBootcampYesNo\"] = \u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m#df[\"BootcampLoan\"] = \u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m#df[\"BootcampLoanTF\"] = \u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mdtypes)\n",
      "File \u001b[1;32md:\\githuborg\\slavong\\python\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   1526\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__nonzero__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1528\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe truth value of a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is ambiguous. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1529\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1530\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"fcc-new-coder-survey.xlsx\",\n",
    "                   sheet_name=\"2017\",\n",
    "                   skiprows=2,\n",
    "                   )\n",
    "print(df.columns)\n",
    "df = df[[\"AttendedBootcamp\",\n",
    "         \"BootcampLoanYesNo\"]]\n",
    "df[\"AttendedBootcampTF\"] = \"TRUE\" if df[\"AttendedBootcamp\"] else \"FALSE\" if not df[\"AttendedBootcamp\"] else None\n",
    "#df[\"AttendedBootcampYesNo\"] = \n",
    "#df[\"BootcampLoan\"] = \n",
    "#df[\"BootcampLoanTF\"] = \n",
    "print(df.dtypes)\n",
    "print(df.sum())\n",
    "print(df.isna().sum())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bool column has NA values in column AttendedBootcamp",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(\u001b[39m\"\u001b[39;49m\u001b[39mfcc-new-coder-survey.xlsx\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      2\u001b[0m                    sheet_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m2017\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      3\u001b[0m                    skiprows\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m                    dtype\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mAttendedBootcamp\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mbool\u001b[39;49m, \n\u001b[0;32m      5\u001b[0m                           \u001b[39m\"\u001b[39;49m\u001b[39mBootcampLoanYesNo\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mbool\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m                           },\n\u001b[0;32m      7\u001b[0m                     true_values\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mYes\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m      8\u001b[0m                     false_values\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mNo\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m df \u001b[39m=\u001b[39m df[[\u001b[39m\"\u001b[39m\u001b[39mAttendedBootcamp\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m          \u001b[39m# \"AttendedBootcampTF\", \u001b[39;00m\n\u001b[0;32m     12\u001b[0m          \u001b[39m# \"AttendedBootcampYesNo\",\u001b[39;00m\n\u001b[0;32m     13\u001b[0m          \u001b[39m# \"BootcampLoan\",\u001b[39;00m\n\u001b[0;32m     14\u001b[0m          \u001b[39m# \"BootcampLoanTF\", \u001b[39;00m\n\u001b[0;32m     15\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mBootcampLoanYesNo\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mdtypes)\n",
      "File \u001b[1;32md:\\githuborg\\slavong\\python\\venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\githuborg\\slavong\\python\\venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\githuborg\\slavong\\python\\venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:490\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    485\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    486\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m     )\n\u001b[0;32m    489\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 490\u001b[0m     data \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mparse(\n\u001b[0;32m    491\u001b[0m         sheet_name\u001b[39m=\u001b[39;49msheet_name,\n\u001b[0;32m    492\u001b[0m         header\u001b[39m=\u001b[39;49mheader,\n\u001b[0;32m    493\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    494\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m    495\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[0;32m    496\u001b[0m         squeeze\u001b[39m=\u001b[39;49msqueeze,\n\u001b[0;32m    497\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    498\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[0;32m    499\u001b[0m         true_values\u001b[39m=\u001b[39;49mtrue_values,\n\u001b[0;32m    500\u001b[0m         false_values\u001b[39m=\u001b[39;49mfalse_values,\n\u001b[0;32m    501\u001b[0m         skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[0;32m    502\u001b[0m         nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[0;32m    503\u001b[0m         na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[0;32m    504\u001b[0m         keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[0;32m    505\u001b[0m         na_filter\u001b[39m=\u001b[39;49mna_filter,\n\u001b[0;32m    506\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    507\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m    508\u001b[0m         date_parser\u001b[39m=\u001b[39;49mdate_parser,\n\u001b[0;32m    509\u001b[0m         thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[0;32m    510\u001b[0m         decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[0;32m    511\u001b[0m         comment\u001b[39m=\u001b[39;49mcomment,\n\u001b[0;32m    512\u001b[0m         skipfooter\u001b[39m=\u001b[39;49mskipfooter,\n\u001b[0;32m    513\u001b[0m         convert_float\u001b[39m=\u001b[39;49mconvert_float,\n\u001b[0;32m    514\u001b[0m         mangle_dupe_cols\u001b[39m=\u001b[39;49mmangle_dupe_cols,\n\u001b[0;32m    515\u001b[0m     )\n\u001b[0;32m    516\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    517\u001b[0m     \u001b[39m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    518\u001b[0m     \u001b[39mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32md:\\githuborg\\slavong\\python\\venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1734\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m   1700\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\n\u001b[0;32m   1701\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1702\u001b[0m     sheet_name: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1721\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m   1722\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, DataFrame] \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1723\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1724\u001b[0m \u001b[39m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1725\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1732\u001b[0m \u001b[39m        DataFrame from the passed in Excel file.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mparse(\n\u001b[0;32m   1735\u001b[0m         sheet_name\u001b[39m=\u001b[39;49msheet_name,\n\u001b[0;32m   1736\u001b[0m         header\u001b[39m=\u001b[39;49mheader,\n\u001b[0;32m   1737\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m   1738\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m   1739\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[0;32m   1740\u001b[0m         squeeze\u001b[39m=\u001b[39;49msqueeze,\n\u001b[0;32m   1741\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[0;32m   1742\u001b[0m         true_values\u001b[39m=\u001b[39;49mtrue_values,\n\u001b[0;32m   1743\u001b[0m         false_values\u001b[39m=\u001b[39;49mfalse_values,\n\u001b[0;32m   1744\u001b[0m         skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[0;32m   1745\u001b[0m         nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[0;32m   1746\u001b[0m         na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[0;32m   1747\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m   1748\u001b[0m         date_parser\u001b[39m=\u001b[39;49mdate_parser,\n\u001b[0;32m   1749\u001b[0m         thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[0;32m   1750\u001b[0m         comment\u001b[39m=\u001b[39;49mcomment,\n\u001b[0;32m   1751\u001b[0m         skipfooter\u001b[39m=\u001b[39;49mskipfooter,\n\u001b[0;32m   1752\u001b[0m         convert_float\u001b[39m=\u001b[39;49mconvert_float,\n\u001b[0;32m   1753\u001b[0m         mangle_dupe_cols\u001b[39m=\u001b[39;49mmangle_dupe_cols,\n\u001b[0;32m   1754\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds,\n\u001b[0;32m   1755\u001b[0m     )\n",
      "File \u001b[1;32md:\\githuborg\\slavong\\python\\venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:891\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     parser \u001b[39m=\u001b[39m TextParser(\n\u001b[0;32m    867\u001b[0m         data,\n\u001b[0;32m    868\u001b[0m         names\u001b[39m=\u001b[39mnames,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m    889\u001b[0m     )\n\u001b[1;32m--> 891\u001b[0m     output[asheetname] \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39;49mread(nrows\u001b[39m=\u001b[39;49mnrows)\n\u001b[0;32m    893\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m squeeze \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(output[asheetname], DataFrame):\n\u001b[0;32m    894\u001b[0m         \u001b[39mif\u001b[39;00m header_names:\n",
      "File \u001b[1;32md:\\githuborg\\slavong\\python\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1779\u001b[0m         nrows\n\u001b[0;32m   1780\u001b[0m     )\n\u001b[0;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\githuborg\\slavong\\python\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:285\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m    282\u001b[0m alldata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rows_to_cols(content)\n\u001b[0;32m    283\u001b[0m data, columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exclude_implicit_index(alldata)\n\u001b[1;32m--> 285\u001b[0m conv_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_data(data)\n\u001b[0;32m    286\u001b[0m columns, conv_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_date_conversions(columns, conv_data)\n\u001b[0;32m    288\u001b[0m index, result_columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_index(\n\u001b[0;32m    289\u001b[0m     conv_data, alldata, columns, indexnamerow\n\u001b[0;32m    290\u001b[0m )\n",
      "File \u001b[1;32md:\\githuborg\\slavong\\python\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:349\u001b[0m, in \u001b[0;36mPythonParser._convert_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    346\u001b[0m     clean_na_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mna_values\n\u001b[0;32m    347\u001b[0m     clean_na_fvalues \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mna_fvalues\n\u001b[1;32m--> 349\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_to_ndarrays(\n\u001b[0;32m    350\u001b[0m     data,\n\u001b[0;32m    351\u001b[0m     clean_na_values,\n\u001b[0;32m    352\u001b[0m     clean_na_fvalues,\n\u001b[0;32m    353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    354\u001b[0m     clean_conv,\n\u001b[0;32m    355\u001b[0m     clean_dtypes,\n\u001b[0;32m    356\u001b[0m )\n",
      "File \u001b[1;32md:\\githuborg\\slavong\\python\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:598\u001b[0m, in \u001b[0;36mParserBase._convert_to_ndarrays\u001b[1;34m(self, dct, na_values, na_fvalues, verbose, converters, dtypes)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    597\u001b[0m     \u001b[39mif\u001b[39;00m is_bool_dtype(cast_type):\n\u001b[1;32m--> 598\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    599\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBool column has NA values in column \u001b[39m\u001b[39m{\u001b[39;00mc\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m         )\n\u001b[0;32m    601\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    602\u001b[0m     \u001b[39m# invalid input to is_bool_dtype\u001b[39;00m\n\u001b[0;32m    603\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Bool column has NA values in column AttendedBootcamp"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"fcc-new-coder-survey.xlsx\",\n",
    "                   sheet_name=\"2017\",\n",
    "                   skiprows=2,\n",
    "                   dtype={\"AttendedBootcamp\": bool, \n",
    "                          \"BootcampLoanYesNo\": bool,\n",
    "                          },\n",
    "                    true_values=[\"Yes\"],\n",
    "                    false_values=[\"No\"],\n",
    ")\n",
    "df = df[[\"AttendedBootcamp\",\n",
    "         # \"AttendedBootcampTF\", \n",
    "         # \"AttendedBootcampYesNo\",\n",
    "         # \"BootcampLoan\",\n",
    "         # \"BootcampLoanTF\", \n",
    "         \"BootcampLoanYesNo\"]]\n",
    "print(df.dtypes)\n",
    "print(df.sum())\n",
    "print(df.isna().sum())\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying imports: parsing dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'AttendedBootcamp', 'BootcampFinish', 'BootcampLoanYesNo',\n",
      "       'BootcampName', 'BootcampRecommend', 'ChildrenNumber', 'CityPopulation',\n",
      "       'CodeEventConferences', 'CodeEventDjangoGirls', 'CodeEventGameJam',\n",
      "       'CodeEventGirlDev', 'CodeEventHackathons', 'CodeEventMeetup',\n",
      "       'CodeEventNodeSchool', 'CodeEventNone', 'CodeEventOther',\n",
      "       'CodeEventRailsBridge', 'CodeEventRailsGirls', 'CodeEventStartUpWknd',\n",
      "       'CodeEventWomenCode', 'CodeEventWorkshop', 'CommuteTime',\n",
      "       'CountryCitizen', 'CountryLive', 'EmploymentField',\n",
      "       'EmploymentFieldOther', 'EmploymentStatus', 'EmploymentStatusOther',\n",
      "       'ExpectedEarning', 'FinanciallySupporting', 'Gender', 'HasChildren',\n",
      "       'HasDebt', 'HasFinancialDependents', 'HasHighSpdInternet',\n",
      "       'HasHomeMortgage', 'HasServedInMilitary', 'HasStudentDebt',\n",
      "       'HomeMortgageOwe', 'HoursLearning', 'ID.x', 'ID.y', 'Income',\n",
      "       'IsEthnicMinority', 'IsReceiveDisabilitiesBenefits', 'IsSoftwareDev',\n",
      "       'IsUnderEmployed', 'JobApplyWhen', 'JobPref', 'JobRelocateYesNo',\n",
      "       'JobRoleInterest', 'JobWherePref', 'LanguageAtHome', 'MaritalStatus',\n",
      "       'MoneyForLearning', 'MonthsProgramming', 'NetworkID', 'Part1EndTime',\n",
      "       'Part1StartTime', 'Part2EndTime', 'Part2StartTime', 'PodcastChangeLog',\n",
      "       'PodcastCodeNewbie', 'PodcastDeveloperTea', 'PodcastDotNetRocks',\n",
      "       'PodcastJsAir', 'PodcastJSJabber', 'PodcastNone', 'PodcastOther',\n",
      "       'PodcastProgrammingThrowDown', 'PodcastRubyRogues', 'PodcastSEDaily',\n",
      "       'PodcastShopTalk', 'PodcastTalkPython', 'PodcastWebAhead',\n",
      "       'ResourceCodecademy', 'ResourceCodeWars', 'ResourceCoursera',\n",
      "       'ResourceEdX', 'ResourceEggHead', 'ResourceFCC', 'ResourceHackerRank',\n",
      "       'ResourceKhanAcademy', 'ResourceLynda', 'ResourceMDN',\n",
      "       'ResourceOdinProj', 'ResourceOther', 'ResourcePluralSight',\n",
      "       'ResourceSkillCrush', 'ResourceStackOverflow', 'ResourceTreehouse',\n",
      "       'ResourceUdacity', 'ResourceUdemy', 'ResourceW3Schools', 'SchoolDegree',\n",
      "       'SchoolMajor', 'StudentDebtOwe'],\n",
      "      dtype='object')\n",
      "Part1StartTime    datetime64[ns]\n",
      "Part1EndTime      datetime64[ns]\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Part1StartTime</th>\n",
       "      <th>Part1EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-29 21:23:13</td>\n",
       "      <td>2016-03-29 21:24:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-29 21:24:59</td>\n",
       "      <td>2016-03-29 21:27:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-29 21:25:37</td>\n",
       "      <td>2016-03-29 21:27:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-29 21:21:37</td>\n",
       "      <td>2016-03-29 21:28:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-29 21:26:22</td>\n",
       "      <td>2016-03-29 21:29:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Part1StartTime        Part1EndTime\n",
       "0 2016-03-29 21:23:13 2016-03-29 21:24:53\n",
       "1 2016-03-29 21:24:59 2016-03-29 21:27:09\n",
       "2 2016-03-29 21:25:37 2016-03-29 21:27:11\n",
       "3 2016-03-29 21:21:37 2016-03-29 21:28:47\n",
       "4 2016-03-29 21:26:22 2016-03-29 21:29:27"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"fcc-new-coder-survey.xlsx\",\n",
    "                   skiprows=2,\n",
    "                   parse_dates=[\"Part1StartTime\",\"Part1EndTime\"],\n",
    "                   )\n",
    "print(df.columns)\n",
    "df = df[[\"Part1StartTime\",\"Part1EndTime\"]]\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>awnd</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>12/01/2017</td>\n",
       "      <td>December</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>52</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>12/02/2017</td>\n",
       "      <td>December</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>48</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>12/03/2017</td>\n",
       "      <td>December</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>12/04/2017</td>\n",
       "      <td>December</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>12/05/2017</td>\n",
       "      <td>December</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>61</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station                         name  latitude  longitude  elevation  \\\n",
       "0  USW00094728  NY CITY CENTRAL PARK, NY US  40.77898  -73.96925       42.7   \n",
       "1  USW00094728  NY CITY CENTRAL PARK, NY US  40.77898  -73.96925       42.7   \n",
       "2  USW00094728  NY CITY CENTRAL PARK, NY US  40.77898  -73.96925       42.7   \n",
       "3  USW00094728  NY CITY CENTRAL PARK, NY US  40.77898  -73.96925       42.7   \n",
       "4  USW00094728  NY CITY CENTRAL PARK, NY US  40.77898  -73.96925       42.7   \n",
       "\n",
       "         date     month  awnd  prcp  snow tavg  tmax  tmin  \n",
       "0  12/01/2017  December  5.37  0.00   0.0         52    42  \n",
       "1  12/02/2017  December  3.13  0.00   0.0         48    39  \n",
       "2  12/03/2017  December  2.01  0.00   0.0         48    42  \n",
       "3  12/04/2017  December  3.58  0.00   0.0         51    40  \n",
       "4  12/05/2017  December  6.71  0.75   0.0         61    50  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(\"sqlite:///data.db\")\n",
    "\n",
    "#print(engine.table_names())\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    weather = pd.read_sql(\"weather\", conn)\n",
    "    # or \n",
    "    weather = pd.read_sql(text(\"SELECT * FROM weather\"), conn)\n",
    "    \n",
    "weather.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing JSON Data and Working with APIs\n",
    "\n",
    "### Introduction to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a      b\n",
       "0  1  alpha\n",
       "1  2   beta"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('[{\"a\":1, \"b\": \"alpha\"}, {\"a\": 2, \"b\": \"beta\"}]',\n",
    "                  orient=\"record\" # or column or split\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a      b\n",
       "0  1  alpha\n",
       "1  2   beta"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('{\"a\":[1,2], \"b\": [\"alpha\",\"beta\"]}',\n",
    "                  orient=\"column\"\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>alpha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a      b\n",
       "0  1  alpha\n",
       "1  2   beta"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('{\"columns\": [\"a\", \"b\"], \"index\": [0,1], \"data\": [[1,\"alpha\"], [2,\"beta\"]]}',\n",
    "                  orient=\"split\"\n",
    "                  )\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "api_url = \"http://api.yelp.com/v3/businesses/search\"\n",
    "params = {\"terms\": \"bookstore\",\n",
    "          \"locartion\": \"San Francisco\"}\n",
    "api_key = \"+++***+++\"\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "response = requests.get(api_url, params=params, headers=headers)\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "df = pd.read_json(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with nested JSONs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "\n",
    "json_normalize(data[\"businesses\"], \n",
    "               record_path=\"categories\",\n",
    "                 meta=..., \n",
    "                 meta_prefix=\"biz_\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Response status code 400 is not OK",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 17\u001b[0m\n\u001b[0;32m     10\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mterm\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcafe\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m     11\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mlocation\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mNYC\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39msort_by\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m     13\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mlimit\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m50\u001b[39m}\n\u001b[0;32m     15\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(api_url, headers\u001b[39m=\u001b[39mheaders, params\u001b[39m=\u001b[39mparams)\n\u001b[1;32m---> 17\u001b[0m \u001b[39massert\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mResponse status code \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m is not OK\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m data \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()\n\u001b[0;32m     21\u001b[0m top_50_cafes \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data[\u001b[39m\"\u001b[39m\u001b[39mbusinesses\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mAssertionError\u001b[0m: Response status code 400 is not OK"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "api_url = 'https://api.yelp.com/v3/businesses/search'\n",
    "\n",
    "api_key = \"xxx\" \n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "params = {\"term\": \"cafe\", \n",
    "          \"location\": \"NYC\",\n",
    "          \"sort_by\": \"rating\", \n",
    "          \"limit\": 50}\n",
    "\n",
    "response = requests.get(api_url, headers=headers, params=params)\n",
    "\n",
    "assert response.status_code == 200, f\"Response status code {response.status_code} is not OK\"\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "top_50_cafes = pd.DataFrame(data[\"businesses\"])\n",
    "\n",
    "cafes = top_50_cafes\n",
    "\n",
    "print(cafes.shape)\n",
    "\n",
    "params = params | {\"offset\": 50}\n",
    "\n",
    "result = requests.get(api_url, headers=headers, params=params)\n",
    "\n",
    "next_50_cafes = json_normalize(result.json()[\"businesses\"])\n",
    "\n",
    "cafes.append(next_50_cafes, ignore_index=True)\n",
    "\n",
    "print(cafes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(df2,\n",
    "         on=\"col\")\n",
    "df.merge(df2,\n",
    "         left_on=\"col1\",\n",
    "        right_on=\"col2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
